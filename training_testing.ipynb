{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "338d3a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import tensorflow_datasets as tfds\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c919cc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from preprocess import process_dir_images, preprocess_lfw\n",
    "from predict import predict_on_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39fdc156",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load LFW dataset from Tensorflow Datasets\n",
    "ds, info = tfds.load('lfw', split='train', with_info=True, as_supervised=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4965c641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 250, 3) \n",
      " b'Tom_Amstutz'\n"
     ]
    }
   ],
   "source": [
    "for label, image in ds.take(1):\n",
    "    print(image.shape, '\\n' ,label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c852e27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the dataset\n",
    "def preprocess_images(label, image):\n",
    "    # If image is 2D (grayscale), add channel dimension\n",
    "    if len(image.shape) == 2:\n",
    "        image = tf.expand_dims(image, axis=-1) \n",
    "    # If image is not RGB, convert to RGB    \n",
    "    if image.shape[-1] != 3:\n",
    "        image = tf.image.grayscale_to_rgb(image)\n",
    "    # Resize the image to a fixed size\n",
    "    image = tf.image.resize(image, [128, 128])\n",
    "    \n",
    "    # Normalize the pixel values to [0, 1]\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    \n",
    "    return image, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ab52d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "face_ds = ds.map(preprocess_images, num_parallel_calls=tf.data.AUTOTUNE).shuffle(35000)\n",
    "#len = len(list(face_ds))\n",
    "face_ds = face_ds.take(3000)  # limiting to 2000 samples for faster training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04e5e0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 3) \n",
      " 1\n"
     ]
    }
   ],
   "source": [
    "for image, label in face_ds.take(1):\n",
    "    print(image.shape, '\\n', label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5b94fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_random_images = 100 # number of random images to be generated form non face data\n",
    "\n",
    "# Generate a dataset of random images\n",
    "random_images_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    tf.random.uniform(shape=(num_random_images, 128, 128, 3), dtype=tf.float32)\n",
    ")\n",
    "\n",
    "# Generate a dataset of zero labels\n",
    "zero_labels_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    tf.zeros(shape=(num_random_images,), dtype=tf.int32)\n",
    ")\n",
    "# Combine random images and labels\n",
    "noface_ds = tf.data.Dataset.zip((random_images_ds, zero_labels_ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "38de9837",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for image, label in noface_ds.take(1):\n",
    "  #  print(image.numpy(), '\\n', label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7548f26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1013 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# load no-face images from a directory\n",
    "\n",
    "dir_images = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"E:/AI-ML-DL/python projects/face detection/Data/Training/\", image_size=(128, 128), \n",
    "    label_mode='int', shuffle=True, \n",
    "    batch_size= None, \n",
    "    class_names=['no_face', 'face']\n",
    "    )\n",
    "\n",
    "#for image, label in dir_images.take(1):\n",
    "#    print(image.numpy(), '\\n', label.numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f3f14b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class names of loaded from directory data:  ['no_face', 'face']\n",
      "the label for loaded dir image is:  0\n",
      "The shape of dir image is :  (128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(\"class names of loaded from directory data: \", dir_images.class_names)\n",
    "img, label = next(iter(dir_images)) # making dataset iterable then taking one sample\n",
    "print(\"the label for loaded dir image is: \",label.numpy())\n",
    "print(\"The shape of dir image is : \",img.shape)\n",
    "\n",
    "#plt.figure()\n",
    "#plt.imshow(img.numpy().astype(\"uint8\"))\n",
    "\n",
    "#for _, label in dir_images.take(1):\n",
    "#    print([int(i) for i in label.numpy()])  # this method will work only on batched data , just print label.numpy() for unbatched data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ac76b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(getattr(dir_images, 'class_names', 'lol'))  # it will print class names because it's dataframe object which have attributes\n",
    "print(getattr(face_ds, 'class_names', 'lol'))   # but as soon as we operate or map a function and create now object it loose attributes just data and labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b0d1eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dir_images(image, label):\n",
    "    # If image is 2D (grayscale), add channel dimension\n",
    "    if len(image.shape) == 2:\n",
    "        image = tf.expand_dims(image, axis=-1) \n",
    "    # If image is not RGB, convert to RGB    \n",
    "    if image.shape[-1] != 3:\n",
    "        image = tf.image.grayscale_to_rgb(image)\n",
    "    # Resize the image to a fixed size\n",
    "    image = tf.image.resize(image, [128, 128])\n",
    "    \n",
    "    # Normalize the pixel values to [0, 1]\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bc22897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.map_op._ParallelMapDataset"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_ds = dir_images.map(process_dir_images, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "type(local_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a08dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for image, label in local_ds.take(1):\n",
    "#    print(image.numpy(), '\\n', label.numpy())\n",
    "#    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77c36af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all datasets here or as you wish\n",
    "dataset = face_ds.concatenate(local_ds).shuffle(1100)\n",
    "#dataset = local_ds.shuffle(1100)\n",
    "\n",
    "dataset_len = len(list(dataset))\n",
    "train_size = int(0.8*dataset_len)\n",
    "\n",
    "train_ds = dataset.take(train_size).shuffle(1000).batch(32).prefetch(tf.data.AUTOTUNE)  # creating batch is necessary for training and prefretching helps in performance(only with GPU)\n",
    "test_ds = dataset.skip(train_size).batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5657b16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(next(iter(train_ds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6e3930",
   "metadata": {},
   "outputs": [],
   "source": [
    "count1 = 0\n",
    "count0 = 0\n",
    "for image, label in train_ds:\n",
    "    for lab in label:\n",
    "         if lab ==1: \n",
    "             # print(image.shape, '\\n', label.numpy())\n",
    "             count1 += 1\n",
    "         else:\n",
    "             count0 += 1\n",
    "\n",
    "print(f\"Number of images with face: {count1}, Number of images without face: {count0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6e31e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "model = Sequential([\n",
    "\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='tanh', input_shape=(128,128,3)), # use activation \"tanh\"\n",
    "    MaxPooling2D(2,2),\n",
    "    Dropout(0.3),\n",
    "\n",
    "\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')])\n",
    "\n",
    "# optimizer \n",
    "optimizer = Adam(learning_rate=0.005)  # you can adjust the learning rate as needed\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cc10d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "model.fit(train_ds, epochs=5, validation_data=test_ds, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bcdb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del model    # delete model to retrain if want to retrain if needed to restart fresh model\n",
    "#tf.keras.backend.clear_session()  # clear the session to free up resources(new method)\n",
    "#tf.compat.v1.reset_default_graph   # clear the session to free up resources(old method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4210acd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to a file\n",
    "#model.save('E:/AI-ML-DL/saved models/face_detection_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4a5e54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# load saved moedl to continue training or evaluation   \n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "model = load_model('E:/AI-ML-DL/saved models/face_detection_model.h5')\n",
    "\n",
    "# Optional: compile if you want to continue training\n",
    "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Optional: continue training\n",
    "#model.fit(dataset, epochs=10, validation_data=dataset, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6485c2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to process loaded single image and make prediction\n",
    "def predict_face(image_path):\n",
    "    img = load_img(image_path, target_size=(128,128))\n",
    "    img = img_to_array(img, dtype='float32')/ 255.0\n",
    "    img = np.expand_dims(img, axis=0) # add batch dimension because model expects a batch of images\n",
    "    prediction = model.predict(img)\n",
    "    print(f\"Prediction shape: {prediction}\")\n",
    "    return prediction[0][0]   # return the predicted probability for the face presence, was shped like [[0.8]] which is 2d array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a750df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Prediction shape: [[0.19721028]]\n",
      "The image is not a face.\n"
     ]
    }
   ],
   "source": [
    "# predict using the model\n",
    "\n",
    "# Single image prediction\n",
    "image_path = \"E:/AI-ML-DL/python projects/face detection/Data/Testing/object3.jpg\"  # single image path\n",
    "prediction = predict_face(image_path)\n",
    "if prediction >0.5:\n",
    "    print(\"The image is a face.\")\n",
    "else:\n",
    "    print(\"The image is not a face.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bbc31c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# load testing dataset from a local directory\n",
    "# give the path with two sub folders: 'face' and 'no_face'\n",
    "test_data = tf.keras.utils.image_dataset_from_directory('E:/AI-ML-DL/python projects/face detection/Data/Testing', image_size=(128, 128), shuffle=False, batch_size=None)\n",
    "\n",
    "# process the images in the test_data\n",
    "test_images = test_data.map(process_dir_images, num_parallel_calls=tf.data.AUTOTUNE).batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe19bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred = model.predict(test_images)\n",
    "pred = model.predict(test_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4232051",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred.shape)\n",
    "print(pred)\n",
    "#pred = np.where(pred > 0.5, 1, 0) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5f9d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "yes = 0\n",
    "no = 0 \n",
    "for pre in pred[:, 0]:  # Assuming pred is a 2D array with shape (num_samples, 1)\n",
    "    if pre > 0.5:\n",
    "        print(pre)\n",
    "        yes += 1\n",
    "    else:\n",
    "        no += 1\n",
    "print(f\"Number of faces detected: {yes}\")\n",
    "print(f\"Number of non-faces detected: {no}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814a85c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict import predict_on_dataset\n",
    "num_batches = 2\n",
    "predict_on_dataset(test_images, num_batches)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "tfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
